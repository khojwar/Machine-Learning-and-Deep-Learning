{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khojwar/Machine-Learning-and-Deep-Learning/blob/main/Machine%20Learning%20with%20tensorflow/HyperParameter_SVM_(one_vs_all_classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zISS8vFDymun"
      },
      "source": [
        "SVM’s is classification tool. It uses one vs all strategy where we calculate probabilities or classification of one class and then put it against rest of classes instead of just finding this is apple, this is orange etc we go with this is not apple, this is apple, this is not apple and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7m1njg5zuP-"
      },
      "source": [
        "### About the Dataset\n",
        "\n",
        "MNIST dataset containing numerical letters from 0 to 9.\n",
        "\n",
        "Using one vs all strategy we **first** find, what is 1 and not 1, what is 2 and not 2 etc. and **then** use it to guess the letters we provide as a test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKaA_ZWjyPwy",
        "outputId": "b37c9638-2be9-4e93-879f-0f5289755125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_openml     # provides easy access to datasets from the OpenML repository.\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"].astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwXReVzb2EVJ"
      },
      "outputs": [],
      "source": [
        "X_train = X[:60000]\n",
        "y_train = y[:60000]\n",
        "X_test = X[60000:]\n",
        "y_test = y[60000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXq1N3E84eRB"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "J9Telpxn4tDf",
        "outputId": "16e9864e-b5e8-4d80-a937-c3c2814a7c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "lin_clf = LinearSVC(random_state=42)    # Create an instance of LinearSVC with a specified random_state for reproducibility (ensuring that the results are consistent across runs).\n",
        "lin_clf.fit(X_train, y_train)   # Train the LinearSVC model using the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfHs6Iwm5Q_m",
        "outputId": "b9e888ee-7498-4b01-d8d6-717b1b4df91b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8348666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lin_clf.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mymdQvCL7zTa"
      },
      "source": [
        "The accuracy score comes out to 83.48  which is pretty bad , let’s try and scale the training dataset to see if any improvements exist -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0CVeRNQ_R6J"
      },
      "source": [
        "**Standardization (or z-score normalization)** is a common preprocessing technique used to *transform numerical features into a standard scale, where the mean is 0 and the standard deviation is 1*. It is particularly important when working with machine learning models that rely on distance-based calculations or optimization algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAku4paY7ReQ",
        "outputId": "8206a33c-3618-4f4d-c5b4-e61742186bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9214"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))   # Convert the data to float32 and then apply standardization to X_train\n",
        "X_test_scaled = scaler.fit_transform(X_test.astype(np.float32))\n",
        "\n",
        "lin_clf = LinearSVC(random_state=42)\n",
        "lin_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = lin_clf.predict(X_train_scaled)\n",
        "accuracy_score(y_train, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IryOWUzYA07a"
      },
      "source": [
        "The accuracy score comes out to 92.10 which is better than before but still not great.\n",
        "\n",
        "#### Can we do more?\n",
        "\n",
        "YES\n",
        "\n",
        "We can use `kernels`\n",
        "\n",
        "In SVM:\n",
        "Kernels are a way in ML to add more flexibility to the algorithm by adding the polynomial degree of the dataset without increasing the features\n",
        "\n",
        "In CNN:\n",
        "**Kernel size** is filter size, refers to the dimensions of the sliding window over the input. Choosing this hyperparameter has a massive impact on the image classification task.\n",
        "\n",
        "For example,\n",
        "* `small kernel sizes` are able to extract a much larger amount of information containing highly local features from the input.\n",
        "* Conversely, a `large kernel size` extracts less information, which leads to a faster reduction in layer dimensions, often leading to worse performance. Large kernels are better suited to extract features that are larger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0esDeX6D5nIu"
      },
      "source": [
        "In the context of `SVC(gamma='scale')`, gamma is one of the hyperparameters of the SVC model. The gamma parameter *controls the influence of individual training samples* on the decision boundary. A **small gamma** value will result in a more extended decision boundary, while a **large gamma** value will make the decision boundary more tightly fit around the data points.\n",
        "\n",
        "Setting `gamma='scale'` means that the *gamma parameter will be automatically calculated based on the inverse of the number of features in the training data*. Specifically, `gamma='scale'` is equivalent to `gamma=1 / (n_features * X.var())` where X is the input feature matrix of the training data. This scaling is useful when features have different units or scales because ***it normalizes the influence of individual features on the decision boundary.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENlqREXp-Nzv",
        "outputId": "287a9043-b960-479b-c0a1-7266e8355cb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9455333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC(gamma='scale')    # Create the SVC model with gamma='scale' . The \"gamma\" parameter controls the influence of individual training samples on the decision boundary.\n",
        "svm_clf.fit(X_train_scaled[:10000], y_train[:10000])    # We use an SVC with an RBF kernel\n",
        "\n",
        "y_pred = svm_clf.predict(X_train_scaled)\n",
        "accuracy_score(y_train, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTt6pRzdG1jw"
      },
      "source": [
        "The accuracy score comes out to be 94.5 which is much better now.\n",
        "\n",
        "Notice how we’ve only train 1/6th of actual dataset thats because the performance cost of this operation is a lot and there are a lot of hyper parameters to tune, since this can work for us let’s do hyperparameter tuning.\n",
        "\n",
        "### What is hyperparameter tuning ?\n",
        "\n",
        "Hyperparameters are properties of the algorithm that help classify or regress the dataset when you increase of decrease them for ex.\n",
        "\n",
        "`lin_clf = LinearSVC(random_state=42)`\n",
        "\n",
        "here `random_state=42` is a hyperparameter that helps keep the seed state set as 42 which helps the algorithm to pick similar random instances which helps in giving `accuracy scores` for same instances.\n",
        "\n",
        "Similarly, each hyperparameter is a property and has it’s own function.\n",
        "\n",
        "There is a technique called cross validation where we use small sets of dataset and check different values of hyperparameters on these small datasets and repeats this exercise for multiple times on multiple small sets. Then you can find the best values of each hyperparameter.\n",
        "\n",
        "The usage of multiple small sets is called `cross val score` and the technique of using random hyperparameter values is called `randomized search`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtxgMyki9ijM"
      },
      "source": [
        "`RandomizedSearchCV` library used for hyperparameter tuning or optimization.\n",
        "\n",
        "When training machine learning models, there are certain hyperparameters (like C, gamma, kernel, etc. for SVM) that cannot be learned from the data and need to be set before training the model. Tuning these hyperparameters can significantly impact the model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Zjc1c29n0J"
      },
      "source": [
        "Let me demonstrate this using code —"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKFR4avEKYqT"
      },
      "source": [
        "`cv=3` -->  3-fold cross-validation.\n",
        "\n",
        "`verbose=0` for no output, `verbose=1` for limited output, and `verbose=2` for more detailed output during the search process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "_nblo-7aFWup",
        "outputId": "8bf6bfb8-ac6c-4fb1-acf6-a140dadab780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] END ....C=8.670950225937865, gamma=0.014210408187382057; total time=  49.9s\n",
            "[CV] END ....C=8.670950225937865, gamma=0.014210408187382057; total time=  50.1s\n",
            "[CV] END ....C=8.670950225937865, gamma=0.014210408187382057; total time=  50.7s\n",
            "[CV] END ......C=7.108003192271348, gamma=0.0815767966228506; total time=  54.2s\n",
            "[CV] END ......C=7.108003192271348, gamma=0.0815767966228506; total time=  57.9s\n",
            "[CV] END ......C=7.108003192271348, gamma=0.0815767966228506; total time=  54.8s\n",
            "[CV] END .....C=5.107080238084402, gamma=0.09789490862822041; total time=  54.4s\n",
            "[CV] END .....C=5.107080238084402, gamma=0.09789490862822041; total time=  54.0s\n",
            "[CV] END .....C=5.107080238084402, gamma=0.09789490862822041; total time=  55.0s\n",
            "[CV] END ....C=9.175079172117236, gamma=0.021927613133928374; total time=  51.4s\n",
            "[CV] END ....C=9.175079172117236, gamma=0.021927613133928374; total time=  52.1s\n",
            "[CV] END ....C=9.175079172117236, gamma=0.021927613133928374; total time=  51.0s\n",
            "[CV] END .....C=6.23391381641797, gamma=0.012568668274275009; total time=  50.6s\n",
            "[CV] END .....C=6.23391381641797, gamma=0.012568668274275009; total time=  49.0s\n",
            "[CV] END .....C=6.23391381641797, gamma=0.012568668274275009; total time=  49.3s\n",
            "[CV] END ....C=8.318910381060268, gamma=0.003274002958818032; total time=  26.0s\n",
            "[CV] END ....C=8.318910381060268, gamma=0.003274002958818032; total time=  25.8s\n",
            "[CV] END ....C=8.318910381060268, gamma=0.003274002958818032; total time=  24.7s\n",
            "[CV] END ....C=5.292177851350065, gamma=0.001409317836785186; total time=  16.1s\n",
            "[CV] END ....C=5.292177851350065, gamma=0.001409317836785186; total time=  15.9s\n",
            "[CV] END ....C=5.292177851350065, gamma=0.001409317836785186; total time=  15.8s\n",
            "[CV] END ....C=2.0553724398195663, gamma=0.05853818642095497; total time=  53.1s\n",
            "[CV] END ....C=2.0553724398195663, gamma=0.05853818642095497; total time=  54.0s\n",
            "[CV] END ....C=2.0553724398195663, gamma=0.05853818642095497; total time=  53.4s\n",
            "[CV] END .....C=10.61134752788826, gamma=0.04294179421237153; total time=  52.3s\n",
            "[CV] END .....C=10.61134752788826, gamma=0.04294179421237153; total time=  53.6s\n",
            "[CV] END .....C=10.61134752788826, gamma=0.04294179421237153; total time=  52.4s\n",
            "[CV] END .....C=4.60942817374343, gamma=0.001654138694595887; total time=  16.9s\n",
            "[CV] END .....C=4.60942817374343, gamma=0.001654138694595887; total time=  17.7s\n",
            "[CV] END .....C=4.60942817374343, gamma=0.001654138694595887; total time=  16.9s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=SVC(),\n",
              "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7bf78b37e8f0>,\n",
              "                                        'gamma': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7bf75536b940>},\n",
              "                   verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=SVC(),\n",
              "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7bf78b37e8f0&gt;,\n",
              "                                        &#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7bf75536b940&gt;},\n",
              "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=SVC(),\n",
              "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7bf78b37e8f0&gt;,\n",
              "                                        &#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7bf75536b940&gt;},\n",
              "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV      # used for hyperparameter tuning or optimization\n",
        "from scipy.stats import reciprocal, uniform\n",
        "\n",
        "# Define the hyperparameter grid to sample from. The \"keys\" of the dictionary are the names of the hyperparameters, and the \"values\" are the corresponding probability distributions from which to sample.\n",
        "param_distributions = {\n",
        "    \"gamma\": reciprocal(0.001, 0.1),\n",
        "    \"C\": uniform(1, 10)\n",
        "    }\n",
        "\n",
        "#Adding all values of hyperparameters in a list from which the values of hyperparameter will randomly inserted as hyperparameter\n",
        "\n",
        "rnd_rearch_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2, cv=3)    # Create the RandomizedSearchCV object\n",
        "rnd_rearch_cv.fit(X_train_scaled[:10000], y_train[:10000])    # Fit the RandomizedSearchCV on the training data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR6hpU-bLym4",
        "outputId": "583f4ca6-1dc7-4137-e96d-99ca49faeb42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9391997988041156"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Get the best hyperparameters and the corresponding model\n",
        "rnd_rearch_cv.best_estimator_\n",
        "rnd_rearch_cv.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "BXForJsrL95X",
        "outputId": "cf154954-8690-4743-f6c0-3c5c31d11834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=5.292177851350065, gamma=0.001409317836785186)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5.292177851350065, gamma=0.001409317836785186)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5.292177851350065, gamma=0.001409317836785186)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "rnd_rearch_cv.best_estimator_.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT68iKIpG0KN"
      },
      "source": [
        "`rmse` (*Root Mean Squared Error*) value ***measures how well the model's predictions*** match the actual target values in the training data. A lower RMSE value indicates better performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNOy5sqyCrD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41724aaf-8f5f-43ca-a0fc-232390403e84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20424658299875342"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_pred = rnd_rearch_cv.best_estimator_.predict(X_train_scaled)    # obtained the best estimator from RandomizedSearchCV as rnd_rearch_cv.best_estimator_ and make predictions on the scaled training data\n",
        "mse = mean_squared_error(y_train, y_pred)   # Calculate the Mean Squared Error (MSE) between the actual and predicted values.\n",
        "np.sqrt(mse)    # Calculate the Root Mean Squared Error (RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N1k8x0dD_70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b62e2e-5afc-43e1-8b7c-a9607bdd2d12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6835934464285041"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "y_pred = rnd_rearch_cv.best_estimator_.predict(X_test_scaled)   # obtained the best estimator from RandomizedSearchCV as rnd_rearch_cv.best_estimator_ and make predictions on the scaled testing data\n",
        "mse = mean_squared_error(y_test, y_pred)    # Calculate the Mean Squared Error (MSE) between the actual and predicted values.\n",
        "np.sqrt(mse)    # Calculate the Root Mean Squared Error (RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy_57a0jENP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0ccf3a-ed9d-4462-816d-d6d271f8b66a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9719"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_pred = rnd_rearch_cv.best_estimator_.predict(X_test_scaled)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My accuracy score came out to be 97.2 which is not excellent but it’s good enough and the algorithm isn’t overfitting.\n",
        "\n",
        "Also, note that we increased accuracy score from 89.5 to 97 which is the real victory here.\n",
        "\n",
        "We first scaled the input’s and then tuned the hyperparameters.We must note that training 60,000 data point’s isn’t easy and might take a lot of time, so be patient."
      ],
      "metadata": {
        "id": "G7bLdVuXnfkx"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPfs04OEIrLHeTyQkiq8CO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}